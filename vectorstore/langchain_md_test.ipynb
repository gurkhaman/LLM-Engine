{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "license: openrail++ tags: - stable-diffusion - text-to-image\n",
      "\n",
      "Stable Diffusion v2 Model Card\n",
      "\n",
      "This model card focuses on the model associated with the Stable Diffusion v2 model, available here.\n",
      "\n",
      "This stable-diffusion-2 model is resumed from stable-di\n"
     ]
    }
   ],
   "source": [
    "md_path = \"services/stable-diffusion-2.md\"\n",
    "loader = UnstructuredMarkdownLoader(md_path)\n",
    "data = loader.load()\n",
    "assert len(data) == 1\n",
    "assert isinstance(data[0], Document)\n",
    "readme_content = data[0].page_content\n",
    "print(readme_content[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 92\n",
      "\n",
      "page_content='license: openrail++ tags: - stable-diffusion - text-to-image' metadata={'source': '/workspaces/composition-blueprint-engine/vectorstore/services/stable-diffusion-2.md', 'category_depth': 0, 'last_modified': '2024-09-01T07:32:57', 'languages': ['eng'], 'filetype': 'text/markdown', 'file_directory': '/workspaces/composition-blueprint-engine/vectorstore/services', 'filename': 'stable-diffusion-2.md', 'category': 'Title', 'element_id': 'a006eaa8de45bf77f46abffe5820cae9'}\n",
      "\n",
      "page_content='Stable Diffusion v2 Model Card' metadata={'source': '/workspaces/composition-blueprint-engine/vectorstore/services/stable-diffusion-2.md', 'category_depth': 0, 'last_modified': '2024-09-01T07:32:57', 'languages': ['eng'], 'filetype': 'text/markdown', 'file_directory': '/workspaces/composition-blueprint-engine/vectorstore/services', 'filename': 'stable-diffusion-2.md', 'category': 'Title', 'element_id': 'a54a75c9a9eb3c871babd089c89d4ec5'}\n",
      "\n",
      "{'Title', 'NarrativeText', 'UncategorizedText', 'ListItem'}\n"
     ]
    }
   ],
   "source": [
    "# Under the hood, Unstructured creates different \"elements\" for different chunks of text\n",
    "\n",
    "# loader = UnstructuredMarkdownLoader(md_path, mode=\"elements\")\n",
    "\n",
    "# data = loader.load()\n",
    "# print(f\"Number of documents: {len(data)}\\n\")\n",
    "\n",
    "# for document in data[:2]:\n",
    "#     print(f\"{document}\\n\")\n",
    "\n",
    "# print(set(document.metadata[\"category\"] for document in data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "md_dir = \"services/\"\n",
    "\n",
    "for filename in os.listdir(md_dir):\n",
    "    if filename.endswith(\".md\"):\n",
    "        md_path = os.path.join(md_dir, filename)\n",
    "        loader = UnstructuredMarkdownLoader(md_path)\n",
    "        data = loader.load()\n",
    "        if data and isinstance(data[0], Document):\n",
    "            documents.append(data[0])\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\"../.env\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = config[\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./chroma_local_db\"\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"tasks\": [\\n    {\\n      \"task_id\": 1,\\n      \"task_description\": \"Process the input images to prepare them for object detection.\",\\n      \"dependencies\": [],\\n      \"selected_service\": \"YOLOS (tiny-sized) model\"\\n    },\\n    {\\n      \"task_id\": 2,\\n      \"task_description\": \"Detect objects in the processed images to identify ambulances.\",\\n      \"dependencies\": [1],\\n      \"selected_service\": \"YOLOS (tiny-sized) model\"\\n    }\\n  ],\\n  \"selected_services\": {\\n    \"service_1\": {\\n      \"name\": \"YOLOS (tiny-sized) model\",\\n      \"description\": \"YOLOS model fine-tuned on COCO 2017 object detection.\"\\n    },\\n    \"service_2\": {\\n      \"name\": \"YOLOS (tiny-sized) model\",\\n      \"description\": \"YOLOS model fine-tuned on COCO 2017 object detection.\"\\n    }\\n  },\\n  \"dependencies\": {\\n    \"task_1\": {\\n      \"input\": \"images\",\\n      \"output\": \"processed_images\"\\n    },\\n    \"task_2\": {\\n      \"input\": \"processed_images\",\\n      \"output\": \"detected_objects\"\\n    }\\n  }\\n}\\n```'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "# Prompt\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "template = (\"You are an AI assistant, expert at requirement decomposition and service composition. \" \n",
    "\"You are provided with various services that might be fit for fulfilling the user's request. \"\n",
    "\"Your job is to break down the user's request and select the appropriate services that will fulfill the decomposed tasks. \"\n",
    "\"If there are not suitable services available to fit the user's requirements, say that it is not possible to do so. \"\n",
    "\"You should give your answer in a structure json output with clear indication of tasks, selected services, and any dependencies (file, values) between these tasks. \"\n",
    "\"{context}\"\n",
    "\"Question: {question}\"\n",
    "\"Helpful Answer: \"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke(\n",
    "    \"I have a turtlebot with low processing power that is taking low quality pictures. I want to find if there are any ambulances in the pictures. Assume the images are provided to you.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
